# Clean Architecture in Mental Health NLP
# Clean Architecture pour un Projet NLP en SantÃ© Mentale

## Introduction

Cette architecture suit les principes de la **Clean Architecture** (Robert C. Martin) appliquÃ©s Ã  un projet de classification NLP pour la dÃ©tection de problÃ¨mes de santÃ© mentale. L'objectif est de crÃ©er un systÃ¨me maintenable, testable et Ã©volutif en sÃ©parant clairement les responsabilitÃ©s.

### Principe fondamental : La rÃ¨gle de dÃ©pendance

Les dÃ©pendances pointent toujours **vers l'intÃ©rieur** :
```
Interface â†’ Infrastructure â†’ Application â†’ Domain
   (UI)      (Frameworks)    (Use Cases)   (MÃ©tier)
```

Le **domaine** (cÅ“ur mÃ©tier) ne connaÃ®t rien des frameworks, bases de donnÃ©es ou interfaces utilisateur. C'est l'infrastructure qui implÃ©mente les contrats dÃ©finis par le domaine.

---

## Vue d'ensemble des couches

### ğŸ¯ Domain (CÅ“ur mÃ©tier)
**RÃ´le** : Contient la logique mÃ©tier pure, indÃ©pendante de toute technologie.

**Composants** :
- **Entities** : Objets mÃ©tier (Document, Label)
- **Ports** : Interfaces que l'infrastructure devra implÃ©menter
- **Services** : Logique mÃ©tier rÃ©utilisable (nettoyage de texte, validation)

**Interactions** : Ne dÃ©pend de RIEN. Les autres couches dÃ©pendent de lui.

---

### ğŸ”„ Application (Orchestration)
**RÃ´le** : ImplÃ©mente les cas d'usage en orchestrant le domaine.

**Composants** :
- **Use Cases** : ScÃ©narios mÃ©tier (entraÃ®ner un modÃ¨le, prÃ©dire, Ã©valuer)
- **DTOs** : Objets de transfert de donnÃ©es entre couches

**Interactions** :
- â¬‡ï¸ Utilise le **Domain** (entities, ports, services)
- â¬†ï¸ Est appelÃ©e par l'**Infrastructure** ou l'**Interface**

---

### ğŸ”§ Infrastructure (ImplÃ©mentations)
**RÃ´le** : ImplÃ©mente les ports du domaine avec des technologies concrÃ¨tes.

**Composants** :
- **Data** : Adaptateurs pour Kaggle, CSV, bases de donnÃ©es
- **NLP** : ImplÃ©mentations HuggingFace, Keras pour la tokenisation
- **Models** : ModÃ¨les ML concrets (DistilBERT, CNN, RoBERTa)
- **Training** : Framework d'entraÃ®nement (PyTorch, TensorFlow)

**Interactions** :
- â¬‡ï¸ ImplÃ©mente les interfaces du **Domain**
- â¬‡ï¸ Est injectÃ©e dans l'**Application** (dependency injection)

---

### ğŸ–¥ï¸ Interface (Points d'entrÃ©e)
**RÃ´le** : Expose le systÃ¨me au monde extÃ©rieur.

**Composants** :
- **CLI** : Interface en ligne de commande
- *(Futur : API REST, interface web)*

**Interactions** :
- â¬‡ï¸ Appelle l'**Application** (use cases)
- â¬‡ï¸ Instancie et injecte l'**Infrastructure**

---

## Structure dÃ©taillÃ©e avec commentaires

```text
mental-health-nlp/
â”‚
â”œâ”€â”€ data/                                    # ğŸ’¾ DonnÃ©es du projet (gitignored)
â”‚   â”œâ”€â”€ raw/                                # DonnÃ©es brutes tÃ©lÃ©chargÃ©es (Kaggle, etc.)
â”‚   â”œâ”€â”€ processed/                          # Datasets nettoyÃ©s et tokenisÃ©s
â”‚   â””â”€â”€ external/                           # Sources externes (APIs, scraping)
â”‚
â”œâ”€â”€ notebooks/                              # ğŸ“Š Exploration et expÃ©rimentation (prototypage)
â”‚   â”œâ”€â”€ 01_explore_dataset.ipynb           # EDA : distribution des labels, longueur textes
â”‚   â”œâ”€â”€ 02_build_dataset.ipynb             # PrÃ©paration : nettoyage, Ã©quilibrage
â”‚   â”œâ”€â”€ 03_train_distilbert.ipynb          # ExpÃ©rimentation DistilBERT
â”‚   â”œâ”€â”€ 04_train_distilbert_cnn.ipynb      # ExpÃ©rimentation architecture hybride
â”‚   â”œâ”€â”€ 05_train_cnn.ipynb                 # Baseline CNN classique
â”‚   â””â”€â”€ 06_inference.ipynb                 # Tests de prÃ©diction et analyse erreurs
â”‚
â”œâ”€â”€ configs/                                # âš™ï¸ Configuration externalisÃ©e (YAML)
â”‚   â”œâ”€â”€ dataset.yaml                       # Sources, chemins, ratio train/val/test
â”‚   â”œâ”€â”€ distilbert.yaml                    # Learning rate, batch size, epochs, etc.
â”‚   â”œâ”€â”€ distilbert_cnn.yaml                # Config architecture hybride
â”‚   â”œâ”€â”€ cnn.yaml                           # HyperparamÃ¨tres CNN (filters, kernel_size)
â”‚   â””â”€â”€ roberta.yaml                       # Config RoBERTa (fine-tuning)
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ mh_nlp/                            # ğŸ“¦ Package principal
â”‚       â”‚
â”‚       â”œâ”€â”€ domain/                         # ğŸ¯ COUCHE DOMAINE (Clean Core)
â”‚       â”‚   â”‚                              # â†’ Logique mÃ©tier pure
â”‚       â”‚   â”‚                              # â†’ ZÃ‰RO dÃ©pendance externe
â”‚       â”‚   â”‚                              # â†’ DÃ©finit les rÃ¨gles mÃ©tier
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ entities/                  # Objets mÃ©tier riches
â”‚       â”‚   â”‚   â”œâ”€â”€ document.py            # class Document: texte, id, metadata
â”‚       â”‚   â”‚   â”‚                          # â†’ MÃ©thodes : validate(), clean()
â”‚       â”‚   â”‚   â””â”€â”€ label.py               # class Label: nom, id, description
â”‚       â”‚   â”‚                              # â†’ Enum des catÃ©gories (Depression, Anxiety...)
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ ports/                     # ğŸ”Œ Interfaces (Design by Contract)
â”‚       â”‚   â”‚   â”‚                          # â†’ DÃ©finissent "QUOI" sans "COMMENT"
â”‚       â”‚   â”‚   â”œâ”€â”€ tokenizer.py           # Protocol Tokenizer: tokenize(text) -> tokens
â”‚       â”‚   â”‚   â”œâ”€â”€ classifier.py          # Protocol Classifier: predict(), train()
â”‚       â”‚   â”‚   â””â”€â”€ dataset_repository.py  # Protocol Repository: load(), save()
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ services/                  # Services du domaine (logique rÃ©utilisable)
â”‚       â”‚       â””â”€â”€ text_cleaner.py        # clean_text(text) -> cleaned_text
â”‚       â”‚                                  # â†’ RÃ¨gles mÃ©tier : normalisation, stopwords
â”‚       â”‚
â”‚       â”œâ”€â”€ application/                    # ğŸ”„ COUCHE APPLICATION (Use Cases)
â”‚       â”‚   â”‚                              # â†’ Orchestration du domaine
â”‚       â”‚   â”‚                              # â†’ DÃ©pend du Domain (entities, ports)
â”‚       â”‚   â”‚                              # â†’ IndÃ©pendante de l'implÃ©mentation
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ use_cases/                 # ScÃ©narios mÃ©tier (user stories)
â”‚       â”‚   â”‚   â”œâ”€â”€ build_dataset.py       # UC: Charger, nettoyer, sauvegarder dataset
â”‚       â”‚   â”‚   â”‚                          # â†’ Utilise DatasetRepository (port)
â”‚       â”‚   â”‚   â”œâ”€â”€ split_dataset.py       # UC: Diviser en train/val/test (stratifiÃ©)
â”‚       â”‚   â”‚   â”œâ”€â”€ train_model.py         # UC: EntraÃ®ner modÃ¨le + sauvegarder checkpoints
â”‚       â”‚   â”‚   â”‚                          # â†’ Utilise Classifier (port)
â”‚       â”‚   â”‚   â”œâ”€â”€ evaluate_model.py      # UC: Calculer mÃ©triques (F1, accuracy, etc.)
â”‚       â”‚   â”‚   â””â”€â”€ predict.py             # UC: PrÃ©dire label pour nouveau texte
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ dto/                       # Data Transfer Objects (immutables)
â”‚       â”‚       â”œâ”€â”€ prediction_result.py   # RÃ©sultat prÃ©diction (label, confidence)
â”‚       â”‚       â””â”€â”€ training_metrics.py    # MÃ©triques d'entraÃ®nement (loss, accuracy)
â”‚       â”‚
â”‚       â”œâ”€â”€ infrastructure/                 # ğŸ”§ COUCHE INFRASTRUCTURE (ImplÃ©mentations)
â”‚       â”‚   â”‚                              # â†’ ImplÃ©mente les ports du Domain
â”‚       â”‚   â”‚                              # â†’ Contient les dÃ©tails techniques
â”‚       â”‚   â”‚                              # â†’ DÃ©pendances externes autorisÃ©es
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ data/                      # Adaptateurs pour sources de donnÃ©es
â”‚       â”‚   â”‚   â””â”€â”€ kaggle_repository.py   # ImplÃ©mente DatasetRepository avec Kaggle API
â”‚       â”‚   â”‚                              # â†’ Peut Ãªtre remplacÃ© par CSVRepository, etc.
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ nlp/                       # Adaptateurs pour outils NLP
â”‚       â”‚   â”‚   â”œâ”€â”€ hf_tokenizer.py        # ImplÃ©mente Tokenizer avec Transformers
â”‚       â”‚   â”‚   â”‚                          # â†’ AutoTokenizer.from_pretrained()
â”‚       â”‚   â”‚   â””â”€â”€ keras_tokenizer.py     # ImplÃ©mente Tokenizer avec Keras
â”‚       â”‚   â”‚                              # â†’ Tokenizer(num_words=10000)
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ models/                    # ImplÃ©mentations des modÃ¨les ML
â”‚       â”‚   â”‚   â”œâ”€â”€ distilbert_classifier.py     # DistilBertForSequenceClassification
â”‚       â”‚   â”‚   â”œâ”€â”€ distilbert_cnn_classifier.py # Hybrid: DistilBERT + CNN layers
â”‚       â”‚   â”‚   â”œâ”€â”€ roberta_classifier.py        # RoBERTa fine-tuning
â”‚       â”‚   â”‚   â””â”€â”€ cnn_classifier.py            # CNN classique (baseline)
â”‚       â”‚   â”‚   # â†’ Tous implÃ©mentent l'interface Classifier
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ training/                  # Infrastructure d'entraÃ®nement
â”‚       â”‚       â””â”€â”€ torch_trainer.py       # Boucle d'entraÃ®nement PyTorch
â”‚       â”‚                                  # â†’ Callbacks, early stopping, logging
â”‚       â”‚
â”‚       â”œâ”€â”€ interface/                      # ğŸ–¥ï¸ COUCHE INTERFACE (Points d'entrÃ©e)
â”‚       â”‚   â”‚                              # â†’ Exposition du systÃ¨me
â”‚       â”‚   â”‚                              # â†’ Instancie et injecte les dÃ©pendances
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ cli.py                     # CLI avec Typer ou argparse
â”‚       â”‚       # Commandes :
â”‚       â”‚       # - train --model distilbert --config configs/distilbert.yaml
â”‚       â”‚       # - predict --text "I feel anxious" --model saved_model/
â”‚       â”‚       # - evaluate --model saved_model/ --test-data data/test.csv
â”‚       â”‚
â”‚       â””â”€â”€ utils/                         # ğŸ› ï¸ Utilitaires transversaux
â”‚           â”œâ”€â”€ seed.py                    # set_seed(42) pour reproductibilitÃ©
â”‚           â””â”€â”€ logging.py                 # Configuration logger (format, niveau)
â”‚
â”œâ”€â”€ tests/                                  # ğŸ§ª Tests automatisÃ©s (TDD)
â”‚   â”œâ”€â”€ unit/                              # Tests unitaires (domaine isolÃ©)
â”‚   â”‚   â”œâ”€â”€ test_entities.py              # Test Document, Label (validation)
â”‚   â”‚   â””â”€â”€ test_services.py              # Test TextCleaner (mock dependencies)
â”‚   â”‚
â”‚   â”œâ”€â”€ integration/                       # Tests d'intÃ©gration (use cases)
â”‚   â”‚   â”œâ”€â”€ test_train_use_case.py        # Test entraÃ®nement avec mock repository
â”‚   â”‚   â””â”€â”€ test_predict_use_case.py      # Test prÃ©diction end-to-end
â”‚   â”‚
â”‚   â””â”€â”€ e2e/                               # Tests end-to-end (scÃ©narios rÃ©els)
â”‚       â””â”€â”€ test_full_pipeline.py         # Test dataset â†’ train â†’ predict
â”‚
â”œâ”€â”€ .github/workflows/                      # ğŸš€ CI/CD avec GitHub Actions
â”‚   â”œâ”€â”€ ci.yml                             # Lint (ruff), tests (pytest), coverage
â”‚   â””â”€â”€ release.yml                        # Build package, publish to PyPI
â”‚
â”œâ”€â”€ pyproject.toml                         # ğŸ“‹ Configuration projet (Poetry/setuptools)
â”‚   # Dependencies:
â”‚   # - transformers, torch (infrastructure)
â”‚   # - pydantic (domain entities)
â”‚   # - pytest, pytest-cov (tests)
â”‚
â””â”€â”€ README.md                              # ğŸ“– Documentation projet
```

---

## Flux d'exÃ©cution (exemple : EntraÃ®ner un modÃ¨le)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CLI       â”‚  1. Utilisateur lance : python -m mh_nlp train --model distilbert
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Interface (cli.py)        â”‚  2. Parse arguments, charge config YAML
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Infrastructure                        â”‚  3. Instancie les adaptateurs :
â”‚   - KaggleRepository (data)             â”‚     - repository = KaggleRepository()
â”‚   - HFTokenizer (nlp)                   â”‚     - tokenizer = HFTokenizer("distilbert-base")
â”‚   - DistilBertClassifier (models)       â”‚     - model = DistilBertClassifier()
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚  4. Injection de dÃ©pendances
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Application               â”‚  5. ExÃ©cute le use case :
â”‚   TrainModelUseCase         â”‚     use_case = TrainModelUseCase(
â”‚                             â”‚         repository=repository,
â”‚                             â”‚         tokenizer=tokenizer,
â”‚                             â”‚         classifier=model
â”‚                             â”‚     )
â”‚                             â”‚     use_case.execute(config)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Domain                    â”‚  6. Utilise les services :
â”‚   - TextCleaner             â”‚     - Nettoie les textes
â”‚   - Document entities       â”‚     - Valide les documents
â”‚   - Label entities          â”‚     - Encode les labels
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Avantages de cette architecture

### âœ… TestabilitÃ©
- Le domaine est testable sans PyTorch, HuggingFace ou Kaggle
- Les use cases sont testables avec des mocks (repositories, classifiers)
- Tests pyramide : beaucoup d'unit tests, moins d'integration, peu d'e2e

### âœ… FlexibilitÃ©
- Changer de DistilBERT â†’ RoBERTa : modifier uniquement l'infrastructure
- Remplacer Kaggle par une API custom : un seul fichier Ã  changer
- Ajouter une interface web : crÃ©er `interface/web.py` sans toucher au reste

### âœ… MaintenabilitÃ©
- SÃ©paration claire des responsabilitÃ©s
- Code mÃ©tier isolÃ© des frameworks (moins de couplage)
- Plus facile Ã  comprendre et Ã  onboarder de nouveaux dÃ©veloppeurs

### âœ… Ã‰volutivitÃ©
- Ajouter de nouveaux modÃ¨les : implÃ©menter l'interface `Classifier`
- Ajouter de nouvelles sources de donnÃ©es : implÃ©menter `DatasetRepository`
- Migration progressive (ex: PyTorch â†’ JAX) sans rÃ©Ã©crire tout le code